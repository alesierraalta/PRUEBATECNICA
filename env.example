# LLM Summarization Microservice Configuration
# Copy this file to .env and fill in your values

# API Configuration
API_TITLE="LLM Summarization API"
API_VERSION="1.0.0"
API_KEYS_ALLOWED="test_api_key_1,test_api_key_2,dev_api_key_2024"

# LLM Provider
LLM_PROVIDER="gemini"
GEMINI_API_KEY="your_gemini_api_key_here"
GEMINI_MODEL="gemini-pro"

# Timeouts (milliseconds)
REQUEST_TIMEOUT_MS=10000
LLM_TIMEOUT_MS=8000

# Summarization Defaults
SUMMARY_MAX_TOKENS=100
LANG_DEFAULT="auto"
TONE_DEFAULT="neutral"

# Redis Configuration
REDIS_URL="redis://localhost:6379"
REDIS_POOL_MAX_CONNECTIONS=50
CACHE_TTL_SECONDS=3600

# Rate Limiting
ENABLE_RATE_LIMIT=true
RATE_LIMIT_PER_MINUTE=100

# CORS
CORS_ORIGINS="*"

# Logging
LOG_LEVEL="INFO"

# Evaluation
ENABLE_AUTO_EVALUATION=true
EVALUATION_MODEL="all-MiniLM-L6-v2"
